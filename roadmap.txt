A simple text file outlining future features and how to get there
=================================================================

FEATURE PACKAGES
----------------
Full streaming through Cedar client and server
+ Start/Stop recording
+ Use webopus to encode/decode in separate threads
+ Disable input selection while recording
+ Musicians placed in chain automatically
x Only root musician can start recording (eventually host maybe?)
+ Audio recording delayed by x seconds per musician
+ Make sure we don't needlessly create audio nodes when switching audio inputs
+ Features
  + New MasterOutput component that launches the RoomAudioPlayer node and
    includes a gain control and volume bar
  + AudioInputBufferer, which takes raw audio input PCM data, buffers it for a
    bit, then sends it back out to the main thread
  + VolumeBar now displays audio decibel-scaled from 0 to -40 dB
+ Don't patch so crazy man. DONE

Put it on DigitalOcean
+ Put it on a droplet
+ Build the electron app for MacOS and Windows
+ Test that it works on Windows
x See if it works with friends!
+ Set up environment solution

Modifying the chain
+ Two lists: audience and musicians; can move participants between lists
+ Musicians are not added to the chain automatically
+ We can set the delay between musicians manually
+ Need to be able to set musician names
  + Simple: shows name in top-right corner--can edit the field to update name
  + Defaults to a bird or type of tree (probably a bird)
  + Name saved somehow?
  + In the future, we'll let people have profiles with names, and people can
    change their name for the room like in Zoom
+ Cannot update chain during recording
+ Last musician in chain is considered the mixer; first considered host?
+ Real-time name updates
+ Optimize volume bar. Rendering with react-konva was costly
+ Don't let musicians be multiline

Loopback delay calculation
+ Play a ping of a certain frequency (use a "chirp" signal?)
+ Use a bandpass filter to find the peak
+ Measure the delay
x (bonus) Visualize the audio received by the client!
+ This value should be manually editable as well
+ Loopback latency calibration closes if recording starts, and button is
  disabled during recording
+ Default the calibration input to the canonical input
+ Include a volume bar in the calibration card
+ Default loopback latency to nothing, and require setting it before being
  added to the chain
+ Mix multiple input channels into one

Fix bugs
- Input selected (and seen in volume bar) may be different than the one sending
  audio through the chain...?
- Dynamically detect audio quantum size...?
- Sometimes output is crunchy
- Sometimes output is choppy
- Sometimes screen turns white
- Sometimes playback and/or input is delayed too much

Quality-of-life improvements
- Button to "fix audio problems" (short-term solution to resolving audio
  cutting in and out)
- Can live-connect/disconnect audio input devices
- Animated brightness to show audio progression through chain
- Make name obviously editable
- Select your instrument (need to find instrument pack)
- Remove musicians when they leave the room
- The host is the one who creates the room?
- Standby scrollable?
+ "Listen to mic" button
+ Rename "Audience" to "Standby"
+ Don't play room audio when on Standby

Client-side mixing
- Can only see musicians behind you
- Tooltip about the fact that this only mixes for you (maybe just call it
  "Personal Mixer"?)
- Master output and slider
- "Alpha" indicator
- Update README
- Cut down on needless redux actions (from onUpdate calls?)
- Try sending sine wave through Cedar, and inspect resultant waveform
  - I suspect this is due to how we recover from Web Audio API overbuffering
    (queue size > 1) or somehow skipping frames in output (less likely)
  - It is in part the above I think. One thing to probably rule out is opus
    encoding--it does appear that we're encoding/decoding all the data, as
    evidenced by the fact that tracks stay in-sync long-term (our syncing logic
    makes sure we're churning through samples 1:1, but if data were lost,
    tracks would get out of sync)
  - This issue still occurs, even if I disable our syncing logic

Download recordings
- Mixer role?
- Downloads final mix and individual files as zip
- Can pick where to save files--defaults somewhere

Mixer role
- Extra slot below the chain
- Sends their mix directly to the server
- This is what the audience hears
- Standby musicians don't have to be able to hear if they join late (for now)
- This is included in the recording download

Audience app
- Unique link for every room--"click to copy audience invitation link"
- Separate React(?) app
- Indicates whether music is playing
- Plays the stream from the mixer

In-app chat
- Actually use websocket subscriptions?
- People can send links

Set up authentication
- Google auth?

Downtimeless updates
- Use infrastructure-as-code to provision Cedar server
- Use load balancer for downtimeless deploys
- Automatically upload Electron app to CMS
- Landing page?
- Accounts with subscriptions?

Other bugs/features before wider release
- Signed distributions
- Landing page
- Sign up/in page
- Subscription method??
- Remembering being logged in
- Display errors (esp. for streaming failures)
- Free trial?
  - Possibly decrease audio quality after 15 minutes, limit to 4 musicians,
    limit to 2-minute recordings (with toast notification), etc.
- Microphone permission detection broken in Electron
- Auto-updates https://www.electron.build/auto-update
- Auth
- enter and exit room ("active" and "inactive" users... Inactive users in the
  chain are removed from the chain when recording stops)
- Use react-beautiful-dnd sensors to make other people's list changes look less
  janky?
- Little musical instrument icons?

Wider release milestone!

Make web app version public (for ChromeOS, etc.)
- autoplay-policy makes me sad, and we need to get around it: Call
  audiocontext.resume on user interaction? (not necessary in electron)
  https://developers.google.com/web/updates/2017/09/autoplay-policy-changes#webaudio

Allow rejoining stream mid-stream (if you lose your place entirely). This can
be for audience members first, though we should be able to do it for musicians
as well, in theory.
Currently, when a recording starts, we assume:
1. that all clients will start recording at approximately the correct time
2. that all clients receive perfect data from the server (no gaps)
3. that all clients perfectly send *all* input device data to the server (no
   gaps)
I am reasonably confident that we can rely on assumptions (1) and (2) holding
true until we see evidence otherwise. Though I am not as confident about (3)
because I don't know whether the Web Audio API guarantees all audio data passes
through the audio graph lossless (though I would be surprised if that weren't
the case), and the bigger factor: computers freeze and lose connection. In
these cases, we will want a way for clients to jump back into the action, even
without knowing the exact time recording began. To achieve this, I believe we
need these things:
* You can fetch the last x seconds (probably however long the chain is) of
  audio data from the server
* Each chunk of audio data includes an index that corresponds to that index of
  the root audio track
* Each client attaches that index to each chunk they send out
* Clients only buffer audio for playing that matches the position relative to
  the root audio (e.g., there can be gaps in data, but we should be able to
  identify them)
Then and only then can a client hypothetically join an existing stream,
starting wherever they need to relative to root audio (given their position in
the chain).
- Need to save metadata in stream chunks--i.e., chunk index

Cedar audience
- Can join in whenever and hear the audio of the room (definitely need
  rejoining mid-stream to be a thing for this)

FEATURE PACKAGES THAT NEED TO BE SPECCED OUT
--------------------------------------------
Future features
- Use JWT + Google OAuth for authentication
- Display errors (esp. for streaming failures)
  - Maybe allow handle in FeathersHooks to make these pop up if I don't handle
    them in a particular way?
- Server track PATCH endpoint is truly idempotent (returns the same response if
  the same input is received). This will help make us robust to servers that
  die (i.e., it's OK if we don't get the new cursor immediately when writing
  audio data)
- Support multiple channels (stereo+)
- Visualize and allow playback of recordings
- Download recordings
- Lossless audio
- Musician layers/lanes for grouping musicians together
  - Includes server-side mixing of each layer to minimize network data flux
- Possibly put non-audio-streaming data into an RDBMS instead of Redis
- Play track (file, built-in metronome, etc.) alongside root musician (can be
  mixed separately)
- Intercom feature? I really, really hope we don't need this (managing multiple
  input devices sounds like UX hell). But it may be better than using two
  applications for some people
  - One advantage is that it would prevent us from needing to toggle mute on
    and off in Zoom; also doesn't require people to have a separate
    conferencing service (manage two links); UX greatly improved...?
- how to select master output? <-- This was confusion about where the output
  audio goes. I think the OS controls this?
  - Here's a thread about it:
    https://stackoverflow.com/questions/41863094/how-to-select-destination-output-device-using-web-audio-api

WHEN I GET BORED OR IF SOMEONE JOINS THE PROJECT
------------------------------------------------
- Documentation on how the frontend sends and receives audio data (include how
  we compiled webopus)

MISC NOTES
----------
OK, so stuff about audio glitches
+ Link to resources on debugging
- We need to do time stretching for microphone skips (happens sometimes, and we
  CANNOT tolerate it because we need sample n on every audio stream to refer to
  the same time point). We currently play the same frame twice.
- Sometimes rendering audio takes a long time, and we end up with underflow on
  the speaker end of things. We can *maybe* help with this by using a
  SharedArrayBuffer to cut down on message-posting costs. Other than that, I'm
  not sure what's best here.

Outgoing worklet:
- should update the patch endpoint to, if it receives data with the wrong
  cursor,
  * if the incoming data matches the data from that cursor onward, return the
    saved cursor with a 200 (truly idempotent, which is handy for when a server
    dies before responding)
  * if the incoming data does not match the data from that cursor onward, fail
    the request by saying something like, "The provided data is not contiguous
    with/adjacent to previous data"

Incoming worklet:
- NOTE: When we allow client-side gain alteration, this should be handled as a
  worklet param so we can update gain dynamically in real time during playback.

CEDAR TESTING SESSIONS
----------------------
9/28/20
+ how to select master output? <-- This was confusion about where the output
  audio goes. I think the OS controls this?
+ playback button (listen to mic)
+ loopback latency is a pain to set
+ didn’t know could change name—why am I this weird name?
+ worthwhile to see others’ latency? compared to you or to the original
    + know how long to wait for all musicians to hear audio
    + IDEA TIME: Oscillating brightness (like vegas lights) to see sound
      progress through chain
+ in-app chat/way to type messages
+ way to label which instrument (use emoji?)
+ in-app intercom—automatically toggle mute
+ nice to be able to adjust input volume
+ official host designation
+ arbitrary 8-person audience limit
+ remove musicians when leave
+ standby lobby mode—talk and interact (calob)
    + could even be nice for rebel worship scenarios
    + downside could be everyone downloads it
+ mixer role (adjust other people’s latencies & sound) could be admin or secondary role
x public room list—privacy rooms via passwords
x browse list of rooms + number of members
+ audience-only version? webpage? volume controls?
+ share lyrics/pdfs/chord chart
+ native recording
+ app is good! webapp for audience-only version maybe
+ way to mock out other musicians (play in base track). way to experience by oneself. good for click track or base track
+ light mode is ugly
+ note from me to me: be clearer about agenda ahead of time
+ garrett loopback: 90
+ calob loopback: 90 (unverified)
+ daniel loopback: 70
+ emily loopback: 170
+ aly loopback: 175
+ isaac loopback: 145
+ “click to copy audience invitation link”
+ chirp for loopback?
+ looks clean as heck —miranda

10/17/20
- Replay recording and mix live--could also determine loopback latency from this?
- Measuring loopback latency takes ~5 minutes per musician
- Sound quality was actually really good
- White screen of death occurred occasionally (should be easier to solve after
  we capture and display errors properly)
